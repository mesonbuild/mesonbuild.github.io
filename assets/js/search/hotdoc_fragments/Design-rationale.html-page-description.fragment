fragment_downloaded_cb({"url":"Design-rationale.html#page-description","fragment":"A software developer's most important tool is the editor. If you talk\nto coders about the editors they use, you are usually met with massive\nenthusiasm and praise. You will hear how Emacs is the greatest thing\never or how vi is so elegant or how Eclipse's integration features\nmake you so much more productive. You can sense the enthusiasm and\naffection that the people feel towards these programs.\nThe second most important tool, even more important than the compiler,\nis the build system.\nThose are pretty much universally despised.\nThe most positive statement on build systems you can usually get (and\nit might require some coaxing) is something along the lines of well,\nit's a terrible system, but all other options are even worse. It is\neasy to see why this is the case. For starters, commonly used free\nbuild systems have obtuse syntaxes. They use for the most part global\nvariables that are set in random locations so you can never really be\nsure what a given line of code does. They do strange and unpredictable\nthings at every turn.\nLet's illustrate this with a simple example. Suppose we want to run a\nprogram built with GNU Autotools under GDB. The instinctive thing to\ndo is to just run gdb programname. The problem is that this may or\nmay not work. In some cases the executable file is a binary whereas at\nother times it is a wrapper shell script that invokes the real binary\nwhich resides in a hidden subdirectory. GDB invocation fails if the\nbinary is a script but succeeds if it is not. The user has to remember\nthe type of each one of his executables (which is an implementation\ndetail of the build system) just to be able to debug them. Several\nother such pain points can be found in this blog\npost.\nGiven these idiosyncrasies it is no wonder that most people don't want\nto have anything to do with build systems. They'll just copy-paste\ncode that works (somewhat) in one place to another and hope for the\nbest. They actively go out of their way not to understand the system\nbecause the mere thought of it is repulsive. Doing this also provides\na kind of inverse job security. If you don't know tool X, there's less\nchance of finding yourself responsible for its use in your\norganisation. Instead you get to work on more enjoyable things.\nThis leads to a vicious circle. Since people avoid the tools and don't\nwant to deal with them, very few work on improving them. The result is\napathy and stagnation.\nAt its core, building C and C++ code is not a terribly difficult\ntask. In fact, writing a text editor is a lot more complicated and\ntakes more effort. Yet we have lots of very high quality editors but\nonly few build systems with questionable quality and usability.\nSo, in the grand tradition of own-itch-scratching, I decided to run a\nscientific experiment. The purpose of this experiment was to explore\nwhat would it take to build a \"good\" build system. What kind of syntax\nwould suit this problem? What sort of problems would this application\nneed to solve? What sort of solutions would be the most appropriate?\nTo get things started, here is a list of requirements any modern cross-platform build system needs to provide.\nOne of the great virtues of Python is the fact that it is very\nreadable. It is easy to see what a given block of code does. It is\nconcise, clear and easy to understand. The proposed build system must\nbe syntactically and semantically clean. Side effects, global state\nand interrelations must be kept at a minimum or, if possible,\neliminated entirely.\nMost builds are done by developers working on the code. Therefore the\ndefaults must be tailored towards that use case. As an example the\nsystem shall build objects without optimization and with debug\ninformation. It shall make binaries that can be run directly from the\nbuild directory without linker tricks, shell scripts or magic\nenvironment variables.\nThere really is no reason to compile source code without the\nequivalent of -Wall. So enable it by default. A different kind of\nbest practice is the total separation of source and build\ndirectories. All build artifacts must be stored in the build\ndirectory. Writing stray files in the source directory is not\npermitted under any circumstances.\nA lot of free software projects can be used on non-free platforms such\nas Windows or OSX. The system must provide native support for the\ntools of choice on those platforms. In practice this means native\nsupport for Visual Studio and XCode. Having said IDEs invoke external\nbuilder binaries does not count as native support.\nWork on this build system started during the Christmas holidays of 2012.\nThis provides a natural hard cutoff line of 2012/12/24. Any\nplatform, tool or library that was not in active use at that time is\nexplicitly not supported. These include Unixes such as IRIX, SunOS,\nOSF-1, Ubuntu versions older than 12/10, GCC versions older than 4.7\nand so on. If these old versions happen to work, great. If they don't,\nnot a single line of code will be added to the system to work around\ntheir bugs.\nRunning the configuration step on a moderate sized project must not\ntake more than five seconds. Running the compile command on a fully up\nto date tree of 1000 source files must not take more than 0.1 seconds.\nAn example is precompiled headers. Currently no free software build\nsystem provides native support for them. Other examples could include\neasy integration of Valgrind and unit tests, test coverage reporting\nand so on.\nSometimes you just have to compile files with only given compiler\nflags and no others, or install files in weird places. The system must\nallow the user to do this if he really wants to.\nGoing over these requirements it becomes quite apparent that the only\nviable approach is roughly the same as taken by CMake: having a domain\nspecific language to declare the build system. Out of this declaration\na configuration is generated for the backend build system. This can be\na Makefile, Visual Studio or XCode project or anything else.\nThe difference between the proposed DSL and existing ones is that the\nnew one is declarative. It also tries to work on a higher level of\nabstraction than existing systems. As an example, using external\nlibraries in current build systems means manually extracting and\npassing around compiler flags and linker flags. In the proposed system\nthe user just declares that a given build target uses a given external\ndependency. The build system then takes care of passing all flags and\nsettings to their proper locations. This means that the user can focus\non his own code rather than marshalling command line arguments from\none place to another.\nA DSL is more work than the approach taken by SCons, which is to\nprovide the system as a Python library. However it allows us to make\nthe syntax more expressive and prevent certain types of bugs by\ne.g. making certain objects truly immutable. The end result is again\nthe same: less work for the user.\nThe backend for Unix requires a bit more thought. The default choice\nwould be Make. However it is extremely slow. It is not uncommon on\nlarge code bases for Make to take several minutes just to determine\nthat nothing needs to be done. Instead of Make we use\nNinja, which is extremely fast. The\nbackend code is abstracted away from the core, so other backends can\nbe added with relatively little effort.\nEnough design talk, let's get to the code. Before looking at the\nexamples we would like to emphasize that this is not in any way the\nfinal code. It is proof of concept code that works in the system as it\ncurrently exists (February 2013), but may change at any time.\nLet's start simple. Here is the code to compile a single executable binary.\nThis is about as simple as one can get. First you declare the project\nname and the languages it uses. Then you specify the binary to build\nand its sources. The build system will do all the rest. It will add\nproper suffixes (e.g. '.exe' on Windows), set the default compiler\nflags and so on.\nUsually programs have more than one source file. Listing them all in\nthe function call can become unwieldy. That is why the system supports\nkeyword arguments. They look like this.\nExternal dependencies are simple to use.\nIn other build systems you have to manually add the compile and link\nflags from external dependencies to targets. In this system you just\ndeclare that extlibrary is mandatory and that the generated program\nuses that. The build system does all the plumbing for you.\nHere's a slightly more complicated definition. It should still be\nunderstandable.\nFirst we build a shared library named foobar. It is marked\ninstallable, so running ninja install installs it to the library\ndirectory (the system knows which one so the user does not have to\ncare). Then we build a test executable which is linked against the\nlibrary. It will no tbe installed, but instead it is added to the list\nof unit tests, which can be run with the command ninja test.\nAbove we mentioned precompiled headers as a feature not supported by\nother build systems. Here's how you would use them.\nThe main reason other build systems can not provide pch support this\neasily is because they don't enforce certain best practices. Due to\nthe way include paths work, it is impossible to provide pch support\nthat always works with both in-source and out-of-source\nbuilds. Mandating separate build and source directories makes this and\nmany other problems a lot easier.\nThe code for this experiment can be found at the Meson\nrepository. It should be noted\nthat it is not a build system. It is only a proposal for one. It does\nnot work reliably yet. You probably should not use it as the build\nsystem of your project.\nAll that said I hope that this experiment will eventually turn into a\nfull blown build system. For that I need your help. Comments and\nespecially patches are more than welcome.\n"});